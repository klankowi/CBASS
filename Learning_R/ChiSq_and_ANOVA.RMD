---
title: "Chi-square tests and ANOVA"
author: "Katie Lankowicz"
date: "`r Sys.Date()`"
output: html_notebook
---

```{r setup}
knitr::opts_chunk$set(echo = TRUE)

# Delete old data
rm(list=ls())

# Load packages, install nycflights13, rstatix, corrplot if you need to.
library(tidyverse)
library (nycflights13)
library(corrplot)
library(rstatix)
library(ggpubr)
library(nortest)
library(agricolae)
```

Today we'll be working on a dataframe of all flights that departed from New York City-area airports (JFK, LaGuardia, and Newark NJ) in 2013. The dataframe is contained in an R package called `nycflights`, so we don't need to set any working directories or load any external data. Just install the package (if you don't have it, and I don't think you do) and then call the pre-existing dataframe called `flights`. Let's see what it contains.

```{r viewdata}
# Because flights is a pre-prepared dataset in a package, we can use the ? function
# to see information regarding its contents.
?flights

# Check out the contents
summary(flights)
str(flights)
```

## Data cleaning

Let's do some data cleaning. We have some missing values to deal with. We also have some incorrect data types-- R frequently reads what should be factor variables as characters. This means it does not recognize that your categorical variable has levels, and instead it's only reading and saving the data as strings of letters. We can fix all this and remove variables that we will not use in this example.

```{r datacleaning}
# Adapt flight dataset
flights2 <- flights %>% 
  # Save only variables that we want to use
  select(month, day, dep_time, sched_dep_time, dep_delay,
         carrier, origin, dest, time_hour, tailnum) %>% 
  # Remove cancelled flights
  na.omit() %>% 
  # Change data type for carrier, origin, destination to factor
  mutate_if(is.character, as.factor)

# Determine which airports have fewer than 50 arrivals from NYC
uncommon_airports <- flights2 %>% 
  # Group by destination
  group_by(dest) %>% 
  # Summarise results: count number of arrivals to each destination
  summarise(count = n()) %>% 
  # Filter out airports with fewer than 50 arrivals from NYC
  filter(count < 50) %>% 
  # Remove count column
  mutate(count = NULL) %>% 
  # Convert to a vector
  pull(dest) %>% 
  # Remove levels that now have 0 samples
  droplevels()

# Determine which carriers have fewer than 50 departures from NYC
uncommon_carriers <- flights2 %>% 
  # Group by carrier
  group_by(carrier) %>% 
  # Summarize results: count number of times each carrier left NYC
  summarise(count = n()) %>% 
  # Filter out carriers with fewer than 50 total departures from NYC
  filter(count < 50) %>% 
  # Remove count column
  mutate(count = NULL) %>% 
  # Convert to a vector
  pull(carrier) %>% 
  # Remove levels that now have 0 samples
  droplevels() 

# Build negate function
'%notin%' <- function(x,y)!('%in%'(x,y))
# I like this function and use it a lot. It's not included in Base R.
# This is the inverse of "must include," so you can think of it as "must not include"

# Remove uncommon airports from dataset
flights2 <- flights2 %>% 
  filter(dest %notin% uncommon_airports)

# Remove uncommon carriers from dataset
flights2 <- flights2 %>% 
  filter(carrier %notin% uncommon_carriers)

# Check results
table(flights2$dest)
table(flights2$carrier)

# Drop levels with 0 samples
flights2 <- droplevels(flights2)

# View results
summary(flights2)
```

Great. Let's now make a new column where we convert the departure date to day of the week. Typically, we'd have to make sure that the column that contains the date information is understood by R to be a date. Luckily, our input this time has already been structure so R understands it is a date. I will write some code out anyway so you can see how you would tell R that your date is actually a date, but I will comment it out so it doesn't run.

```{r dayofweek}
# Check date structure
str(flights2$time_hour)

# Convert characters to date (don't need to run, it already is a date)
# flights2$time_hour <- as.POSIXct(flights2$time_hour,
#                                  format="%Y-%m-%d %H:%M:%S")

# Convert date-time to day of week
flights2$weekday <- weekdays(flights2$time_hour)

# Convert to factor - put days in order (otherwise they will be alphabetical)
flights2$weekday <- factor(flights2$weekday,
                           levels=c("Sunday", "Monday", "Tuesday",
                                    "Wednesday", "Thursday", "Friday",
                                    "Saturday"))

# View result
summary(flights2)
```

## Chi-square goodness of fit test

Let's test if flights are equally as likely to leave NYC on all days of the week. This is a test where we only have one categorical variable-- day of week. Day of week has 7 levels (Sunday through Saturday).

The test that we'll use to address our question is a Chi-square goodness of fit test. This method tests if the observed distribution of results matches the expected distribution of results under the null hypothesis. In this case, the null hypothesis is that all days of the week have an equal proportion of flights. The alternative hypothesis would be that at least one day of the week does not have an equal proportion of flights. Under our null hypothesis, the expected distribution of flights would be (100% of flights / 7 days per week) 14% of flights taken on each day of the week.

There are some assumptions we must consider before going ahead with this test. Chi-square tests require independence of observations, meaning we can't be using the same participant (flight, day of week, whatever) over time. We know that our data are independent. Chi-square tests also require observations to be mutually exclusive-- we can't have a case where a flight was taken on both Monday and Tuesday. Since the laws of time cannot possibly allow this, we're fine on that front. Finally, Chi-square tests can only be used when we expect there to be 5 or more observations of each outcome. In this case, the flights dataset has more than 328,000 flights. If we expect each day of the week to contain around 14% of flights, we expect more than 45,000 flights for each day of the week. We therefore meet all assumptions and can proceed.

We'll use a confidence level of 95%, so in order to reject our null hypothesis, the p-value will need to be less than 0.05.

```{r chisq-gof}
# Make a table showing the number of NYC flights leaving each day of the week
flight.tab <- table(flights2$weekday)

# What should we expect as the proportion of flights leaving each day if it's all equal?
flight.expect <- 1/7

# View results
flight.tab
flight.expect

# Run chi-square test of proportions
chisq.test(x=flight.tab,            # Call data
           p=rep(flight.expect, 7)) # Call probability: 14.28% on each day of 7 days
```

Our p-value is way smaller than 0.05, indicating that at least one weekday has a significantly different proportion of flights than we would expect if all weekdays contained the same number of flights. Let's make some calculations and a plot to determine which days of the week have a different proportion of flights than what we expect under the null hypothesis.

```{r chisq-gofvis}
# Initialize dataframe to save results
flight.df <- as.data.frame(flight.tab)
colnames(flight.df) <- c('Weekday', 'Flights')

# Determine proportion of flights taken on each day
flight.df$Proportion <- flight.df$Flights / nrow(flights2)

# View result
head(flight.df)

# Determine confidence intervals for observed vs. expected
# Loop through rows (days of the week)
for(i in 1:nrow(flight.df)){
  # Calculate and save low confidence interval for each day
  flight.df$CI.low[i] <- binom.test(x=flight.df$Flights[i], 
           n=nrow(flights2),
           p=(1/7), 
           alternative = "two.sided",
           conf.level = 0.95)$conf.int[1]
  # Calculate and save high confidence interval for each day
  flight.df$CI.high[i] <- binom.test(x=flight.df$Flights[i], 
         n=nrow(flights2),
         p=(1/7), 
         alternative = "two.sided",
         conf.level = 0.95)$conf.int[2]
}

# View result
flight.df

# Make a barplot of observed vs. expected with confidence intervals
ggplot(data=flight.df, aes(x=Weekday, y=Proportion)) +
  geom_bar(stat="identity", fill='darkgray') +
  geom_hline(yintercept=1/7) +
  geom_errorbar(data=flight.df,
                aes(ymin=CI.low,
                    ymax=CI.high),
                width=0.0)

```

This is a barplot showing the proportion of flights taken each week day (bar height) and the 95% confidence interval of what we expect the true proportion of flights taken each day to be (little vertical line on each bar). We also have plotted a horizontal line showing the expected proportion of flights taken each day.

Notice that none of our confidence intervals (vertical lines) cross over our expected proportion (horizontal line). This means all of the days of the week have significantly different proportions of flights than what we would expect if the distribution was equal on each day. Sunday and Saturday have fewer flights than expected and Monday-Friday all have more flights than expected.

## Chi-square test of independence

Let's test if there is an association between Carrier and Day of Week. The outcome will tell us if our carriers are equally as likely to depart from NYC airports all days of the week, or if any carrier is more likely to depart on specific days of the week. Both carrier and day of the week are categorical variables, and both have several levels. Day of week obviously has 7 levels, and carrier has 15 levels.

The test we'll use to determine the answer is a Chi-square test of independence. NOTE THAT THIS IS A DIFFERENT CHI-SQUARE TEST THAN THE ONE WE JUST RAN. Our previous test was a goodness of fit test, in which we only use one categorical variable. This test requires two categorical variables. The rest of our assumptions are the same-- we must have independent, mutually exclusive samples. We already know this to be true. We also must have an expected count of at least 5 samples per outcome. In this case, our smallest carrier (HA, Hawaiian airlines) has 342 total departures from NYC in this dataset. We would therefore expect 342 departures / 7 days per week = around 49 departures per weekday. We definitely meet the final assumption.

The null hypothesis of the Chi-square test of independence is that carrier and day of week are independent of each other. The alternative hypothesis is that there is an association between carrier and day of week. We will use a confidence level of 95%, which means to reject our null hypothesis, the p-value of the test outcome will need to be less than 0.05.

```{r chisq-independence}
# Make a contingency table to count number of departures on each day of the week
# by each carrier.
dep.table <- table(flights2$carrier, flights2$weekday)

# Run Chi-square test of independence
chisq.test(dep.table)
```

The p-value is very small. This indicates that we have enough evidence to reject the null hypothesis and accept the alternative. We can say that some carriers are more likely to depart on certain days of the week. Let's see if we can determine which carriers these are, and which days they're more likely to depart.

To get some idea of what is going on, we will use a mosaic plot. 

```{r chisq-outcome}
# Create mosaic plot
mosaicplot(dep.table,             # Call data
           shade = TRUE,          # Set option to color by residual
           las=2,                 # Set axis labels for better plot visualization
           main = "Weekday departures by airline carrier") # Plot title

```

In this plot, days of the week are on the Y axis and airline carriers are on the X axis. Notice that the columns of this plot are different widths-- this is so you can determine the relative frequency of each outcome. For example, the UA column is very wide and the YV column is very thin. This is because way more UA flights depart from NYC airports than YV flights. UA is the call sign for United (a huge company) and YV is the call sign for Mesa Airlines, a tiny regional company from Arizona. 

Some boxes are colored red or blue. Red colors indicate a negative association (less likely than the null hypothesis would indicate) and blue colors indicate a positive association (more likely than the null hypothesis would indicate). The saturation (strength) of the color indicates the strength of that association. Boxes without a color do not have an association between that airline and that day of the week.

From the plot, we can see that most airlines have some sort of weekday pattern of flights. For example, United Airlines (UA) has fewer flights on Saturdays and Sundays than we would expect if the null hypothesis of no association was true. Endeavor Airlines (9E) has more flights on Saturday than would be expected if the null hypothesis of no association was true.

It's kind of hard to determine what's going on in those super-thin columns. Let's adjust our visualization so that all columns are the same width, regardless of number of departures. 

```{r chisq-residuals}
# Save chi-square results
chisq <- chisq.test(dep.table)

# Pull residuals
round(chisq$residuals, 2)

# Plot Pearson correlation of residuals
corrplot(t(chisq$residuals), # Transpose so it's shaped the same as prev. plot
         is.cor = FALSE) # Tell R this isn't traditional correlation matrix
```

This plot is functionally the same as the previous one. It gives us all the same information, it just does so in a way that makes all the columns an equal size. Now we can more clearly see what is going on with small carriers like AS (Alaska Airlines), F9 (Frontier), and FL (AirTran Airways). 

We can make a quantitative determination of which cell in our mosaic plot is contributing the most weight to our result. To do this, we will calculate and retain the chi-square value for each cell, then pull the residual values for each cell.

```{r chisq-contribution}
# Calculate relative contribution of each cell to overall result 
# (values are percents)
contrib <- 100*chisq$residuals^2/chisq$statistic
round(t(contrib), 2)

# Visualize contribution
corrplot(t(contrib), is.cor = FALSE)
```

So we have some very strong associations that contribute a lot to the overall result. Carrier B6 (JetBlue) has a super strong association with Saturdays-- the above plots indicate that they are far more likely to depart on Saturdays than we would expect if there was no association. Other strong results are Saturday departures for carriers EV (ExpressJet) and US (US Express). Note that according to the above plots, these carriers are far LESS likely to depart on Saturdays than one would expect if there was no association. This is the opposite from what we have seen with JetBlue. Make sure that you understand that the contribution plot only tells us how much each cell affects the overall outcome of the test (the p-value), and does not indicate the direction of the association (positive or negative).

## Analysis of Variance (ANOVA)

Chi-square tests of independence determine association between two categorical variables, each with multiple (2 or more) levels. What if we want to test the relationship between a categorical variable with many (3 or more) levels and a quantitative variable? For that, we would use Analysis of Variance (or ANOVA) tests. We'll continue to use the flights dataset.

Let's test if mean delay time varies by NYC airport (remember we have data for JFK, LaGuardia, and Newark NJ). We'll use airport as the explanatory variable and departure delay time as the response variable. Origin airport is a categorical variable. Departure delay time is a numeric variable. It's reported as minutes away from the scheduled departure. Negative values are flights that left earlier than they were supposed to, while positive values are flights that left later than they were supposed to.

The idea behind the ANOVA test is very simple: if the average variation between groups (variation in delay between airports) is large enough compared to the average variation within groups (variation in delay within airports), then you could conclude that at least one group mean is not equal to the others. Thus, itâ€™s possible to evaluate whether the differences between the group means are significant by comparing the two variance estimates. This is why the method is called analysis of variance even though the main goal is to compare the group means.

We need to think about the assumptions of ANOVA. First of all, it requires a categorical variable and a numeric variable. We've already checked that. ANOVA also requires independence of observations. We already have addressed this too, we know that we aren't using repeated measures of the same flight. Finally, we need to check for outliers, normality, and equal variance between groups. We will check for outliers before performing the test and remove any extreme outliers. We will save checking normality and equality of variance for when we have residuals from our model. By waiting until we have residuals, we can look at normality and variance for all groups together. This is easier than checking normality and variance for each day separately, which we would have to do if we weren't using residuals.

We will begin by doing some light data cleaning, then check for outliers.

```{r check-assumptions}
# Clean data-- keep only variables we care about for this test.
flights2 <- dplyr::select(flights2,
                          origin, dest, tailnum, time_hour, dep_delay)

# Qualitatively check for outliers
ggplot(data=flights2, aes(x=origin, y=dep_delay))+
  geom_boxplot()
# Boxplot indicates many outliers

# Quantitatively check for outliers
outlier.check <- flights2 %>% 
  group_by(origin) %>%
  identify_outliers(dep_delay)
nrow(outlier.check[outlier.check$is.extreme==TRUE,])
# 27,422 flights have extreme outliers. We must remove these extreme outliers, but
# we can keep the outliers that are not extreme.

# Merge outlier check to our data so we know which observations are extreme
flights3 <- merge(flights2, outlier.check,
                      by=c('origin', 'dest', 'tailnum', 'time_hour',
                           'dep_delay'),
                  all.x=TRUE)

# Remove outliers
flights3 <- flights3[flights3$is.extreme == FALSE |       # Keep non-extreme outliers
                       is.na(flights3$is.extreme) == TRUE,] # Keep non-outliers.
  
```

We have addressed our outliers. Let's set up a basic boxplot visualization of our data by origin airport.

```{r boxplot}
# Create boxplot using ggplot
ggplot(data=flights3, aes(x=origin, y=dep_delay)) +
  geom_boxplot(alpha=0.4) +
  xlab('Origin airport') +
  ylab('Minutes delayed') +
  theme(axis.text.x=element_text(size=12),
        axis.text.y=element_text(size=12),
        axis.title.x=element_text(size=14),
        axis.title.y=element_text(size=14),
        panel.background = element_blank(),
        panel.grid.major = element_line(color='lightgray'))

```

Judging by eye, it looks like all airports have a quicker departure than expected given the schedule (they have negative mean minutes delayed). LaGuardia gets people out the door fastest, followed by JFK, and finally Newark has the worst delay stats. Let's set up our ANOVA model to make a quantitative determination of the difference in mean delay time between these three airports.

```{r anova}
# Run ANOVA
res_aov <- aov(dep_delay ~ origin,
  data = flights3
)

# View results
summary(res_aov)

```

We now have our outcome. The p-value column shows us that the mean delay time is significantly different between the levels of origin airport (Newark NJ, JFK, and LaGuardia). To quantitatively determine which airports are significantly different to each other, we need to run a "post-hoc" (after the fact) test.

```{r posthoc}
# Run Tukey's post-hoc test to determine which airports are different
TukeyHSD(res_aov, "origin", conf.level = 0.95)

# Plot pairwise comparisons
plot(TukeyHSD(res_aov))
```

Both the post-hoc test and the plot show us the same thing: it looks like all possible pairs of airport comparisons are significantly different. If the model residuals indicate we meet all the assumptions of ANOVA, we say that LaGuardia has a significantly shorter delay time than both JFK and Newark, that JFK has a signifcantly shorter delay time than Newark, and that Newark has a significantly longer delay time than both JFK and LaGuardia.

Let's go back and address the assumptions of normality and equality of variance, starting with normality.

```{r assumptions-normality}
# Plot model residuals in a QQ plot
plot(res_aov, 2)

# Quantitative tests of normality
# Usually you'd use a Shapiro-Wilk test, but we actually have too many samples.
# shapiro.test(res_aov$residuals)

# Instead, we'll use an Anderson-Darling test.
# The null hypothesis is normality. The alternative hypothesis is non-normally distributed
# residuals. We'll use a confidence level of 95%.
ad.test(res_aov$residuals)
```

The QQ plot of residuals shows us that we have a huge departure from normality. The Anderson-Darling test of normality quantitatively shows us the same thing-- the data are not normal. We have more than 300,000 samples (so many!) so if this is our only problem, we may get away with it. Let's check the assumption of equal variance. 

```{r assumptions-variance}
# Plot distribution of residuals
plot(res_aov, 1)

# Quantitative determination of equality of variance
# The null hypothesis is that all groups have equal variance. The alternative hypothesis
# is that at least one group has significantly different variance. We'll use a confidence
# level of 95%.
levene_test(dep_delay ~ origin, data=flights3)
```

The plot doesn't give us a ton of useful information here. However, we can quantitatively assess equality of variance with a Levene test. The test outcome has a very low p-value, indicating that the groups do not have equal variance.

So, these data are not good candidates for parametric assessments like ANOVA! Instead, we can shift to non-parametric methods of assessing means. We'll use the Kruskal-Wallis test, which does not have assumptions of normality or equal variance like ANOVA. It otherwise does functionally the same thing--tests if the means of two groups are equal.

## Kruskal-Wallis tests

The only assumptions needed for a Kruskal-Wallis test are that the samples are random and mutually independent. We already know that we are not using the same flight multiple times. We can proceed with the test.

```{r kruskalwallis}
# Run K-W test
kruskal.test(flights3$dep_delay,
             flights3$origin)
```

Once again, the p-value indicates that at least one pairwise comparison of our three airports has significantly different mean delay time. We need to run a different post-hoc test to determine which pairs have different means. For non-parametric data, we use the Dunn test for this.

```{r dunntest}
agricolae::kruskal(y=flights3$dep_delay, 
                        trt=flights3$origin, 
                        alpha=0.05, 
                        p.adj='bonferroni', 
                        group=TRUE,
                        console=TRUE)
```

And again, it looks like all three airports have mean departure delays that are significantly different to each other. We can check the `groups` column of our Dunn test outcome to confirm-- all three airports have different letters, which indicates they are different from each other. If, for example, JFK and LaGuardia were both labelled "b", this would mean that their mean departure delay times were not significantly different to each other.

Because Kruskal-Wallis tests do not need to meet the assumptions of normality and equality of variance like ANOVA, we can now certify these results. LaGuardia has the shortest mean departure delay time, JFK's delay time is significantly longer than LaGuardia but also significantly shorter than Newark NJ, and Newark NJ has significantly longer departure delay times than both JFK and LaGuardia.